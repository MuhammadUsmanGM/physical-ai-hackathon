"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[8017],{123:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"The-Robotic-Nervous-System/Python-Agents-ROS-Bridge/python-agents-ros-bridge","title":"Bridging Python AI Agents to ROS Controllers","description":"Introduction","source":"@site/docs/02-The-Robotic-Nervous-System/07-Python-Agents-ROS-Bridge/index.md","sourceDirName":"02-The-Robotic-Nervous-System/07-Python-Agents-ROS-Bridge","slug":"/module-02/python-agents-ros-bridge","permalink":"/physical-ai-hackathon/docs/module-02/python-agents-ros-bridge","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/02-The-Robotic-Nervous-System/07-Python-Agents-ROS-Bridge/index.md","tags":[],"version":"current","frontMatter":{"id":"python-agents-ros-bridge","title":"Bridging Python AI Agents to ROS Controllers","slug":"/module-02/python-agents-ros-bridge"},"sidebar":"tutorialSidebar","previous":{"title":"Launch Files and Parameter Management","permalink":"/physical-ai-hackathon/docs/module-02/launch-files-parameters"},"next":{"title":"The Digital Twin (Gazebo & Unity)","permalink":"/physical-ai-hackathon/docs/module-03"}}');var a=r(4848),o=r(8453);const i={id:"python-agents-ros-bridge",title:"Bridging Python AI Agents to ROS Controllers",slug:"/module-02/python-agents-ros-bridge"},s="Bridging Python AI Agents to ROS Controllers",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"Why Bridge AI and ROS?",id:"why-bridge-ai-and-ros",level:2},{value:"AI Agent Strengths:",id:"ai-agent-strengths",level:3},{value:"ROS Controller Strengths:",id:"ros-controller-strengths",level:3},{value:"The Bridge:",id:"the-bridge",level:3},{value:"Pattern 1: LLM-Based Task Planner",id:"pattern-1-llm-based-task-planner",level:2},{value:"Use Case: Natural Language Robot Control",id:"use-case-natural-language-robot-control",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Pattern 2: Reinforcement Learning Agent",id:"pattern-2-reinforcement-learning-agent",level:2},{value:"Use Case: Learned Locomotion Control",id:"use-case-learned-locomotion-control",level:3},{value:"Pattern 3: State Machine with AI Decision Making",id:"pattern-3-state-machine-with-ai-decision-making",level:2},{value:"Use Case: Autonomous Behavior Coordination",id:"use-case-autonomous-behavior-coordination",level:3},{value:"Best Practices for AI-ROS Integration",id:"best-practices-for-ai-ros-integration",level:2},{value:"1. Separate Concerns",id:"1-separate-concerns",level:3},{value:"2. Handle Timing Carefully",id:"2-handle-timing-carefully",level:3},{value:"3. Implement Safety Checks",id:"3-implement-safety-checks",level:3},{value:"4. Provide Rich Feedback",id:"4-provide-rich-feedback",level:3},{value:"Complete Integration Example",id:"complete-integration-example",level:2},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"bridging-python-ai-agents-to-ros-controllers",children:"Bridging Python AI Agents to ROS Controllers"})}),"\n",(0,a.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(e.p,{children:["Modern humanoid robots require ",(0,a.jsx)(e.strong,{children:"intelligent decision-making"})," combined with ",(0,a.jsx)(e.strong,{children:"precise physical control"}),". This chapter shows how to integrate AI agents (using LLMs, reinforcement learning, or classical AI) with ROS 2 controllers using ",(0,a.jsx)(e.code,{children:"rclpy"}),". You'll learn to build systems where AI makes high-level decisions while ROS handles low-level robot control."]}),"\n",(0,a.jsx)(e.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-mermaid",children:'graph TB\r\n    subgraph "AI Agent Layer"\r\n        LLM[LLM / AI Model]\r\n        PLANNER[Task Planner]\r\n        DECISION[Decision Maker]\r\n    end\r\n    \r\n    subgraph "Bridge Layer (rclpy)"\r\n        BRIDGE[Python ROS Bridge]\r\n        STATE[State Manager]\r\n        TRANSLATOR[Command Translator]\r\n    end\r\n    \r\n    subgraph "ROS Control Layer"\r\n        ACTIONS[Action Servers]\r\n        SERVICES[Service Servers]\r\n        TOPICS[Topic Publishers]\r\n    end\r\n    \r\n    subgraph "Robot Hardware"\r\n        MOTORS[Motor Controllers]\r\n        SENSORS[Sensors]\r\n    end\r\n    \r\n    LLM --\x3e PLANNER\r\n    PLANNER --\x3e DECISION\r\n    DECISION --\x3e BRIDGE\r\n    BRIDGE --\x3e STATE\r\n    BRIDGE --\x3e TRANSLATOR\r\n    TRANSLATOR --\x3e ACTIONS\r\n    TRANSLATOR --\x3e SERVICES\r\n    TRANSLATOR --\x3e TOPICS\r\n    ACTIONS --\x3e MOTORS\r\n    TOPICS --\x3e MOTORS\r\n    SENSORS --\x3e STATE\r\n    STATE --\x3e DECISION\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"why-bridge-ai-and-ros",children:"Why Bridge AI and ROS?"}),"\n",(0,a.jsx)(e.h3,{id:"ai-agent-strengths",children:"AI Agent Strengths:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"High-level reasoning and planning"}),"\n",(0,a.jsx)(e.li,{children:"Natural language understanding"}),"\n",(0,a.jsx)(e.li,{children:"Learning from experience"}),"\n",(0,a.jsx)(e.li,{children:"Handling uncertainty"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"ros-controller-strengths",children:"ROS Controller Strengths:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Real-time motor control"}),"\n",(0,a.jsx)(e.li,{children:"Sensor data processing"}),"\n",(0,a.jsx)(e.li,{children:"Safety guarantees"}),"\n",(0,a.jsx)(e.li,{children:"Hardware abstraction"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"the-bridge",children:"The Bridge:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Translates AI decisions to robot actions"}),"\n",(0,a.jsx)(e.li,{children:"Manages state between AI and hardware"}),"\n",(0,a.jsx)(e.li,{children:"Handles timing and synchronization"}),"\n",(0,a.jsx)(e.li,{children:"Provides feedback to AI"}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"pattern-1-llm-based-task-planner",children:"Pattern 1: LLM-Based Task Planner"}),"\n",(0,a.jsx)(e.h3,{id:"use-case-natural-language-robot-control",children:"Use Case: Natural Language Robot Control"}),"\n",(0,a.jsx)(e.p,{children:'"Walk to the kitchen and pick up the cup"'}),"\n",(0,a.jsx)(e.h3,{id:"implementation",children:"Implementation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nLLM-based task planner that translates natural language to ROS actions\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom rclpy.action import ActionClient\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import PoseStamped\r\nimport openai\r\nimport json\r\n\r\nclass LLMTaskPlanner(Node):\r\n    """\r\n    Bridges OpenAI GPT with ROS 2 action servers for humanoid control.\r\n    """\r\n    \r\n    def __init__(self):\r\n        super().__init__(\'llm_task_planner\')\r\n        \r\n        # Parameters\r\n        self.declare_parameter(\'openai_api_key\', \'\')\r\n        self.declare_parameter(\'model\', \'gpt-4\')\r\n        \r\n        api_key = self.get_parameter(\'openai_api_key\').value\r\n        model = self.get_parameter(\'model\').value\r\n        \r\n        # Initialize OpenAI client\r\n        self.client = openai.Client(api_key=api_key)\r\n        self.model = model\r\n        \r\n        # Subscribe to voice commands\r\n        self.command_sub = self.create_subscription(\r\n            String,\r\n            \'voice_command\',\r\n            self.command_callback,\r\n            10\r\n        )\r\n        \r\n        # Action clients for robot control\r\n        self.nav_client = ActionClient(self, NavigateToPoint, \'navigate_to_point\')\r\n        self.manip_client = ActionClient(self, PickObject, \'pick_object\')\r\n        \r\n        # Publisher for status updates\r\n        self.status_pub = self.create_publisher(String, \'task_status\', 10)\r\n        \r\n        # System prompt for the LLM\r\n        self.system_prompt = """You are a robot task planner. Convert natural language commands into structured robot actions.\r\n\r\nAvailable actions:\r\n1. navigate(x, y, theta) - Move to position\r\n2. pick(object_name) - Pick up an object\r\n3. place(object_name, x, y) - Place object at location\r\n4. wait(duration) - Wait for specified seconds\r\n\r\nRespond with JSON array of actions. Example:\r\n{"actions": [\r\n    {"type": "navigate", "x": 5.0, "y": 2.0, "theta": 0.0},\r\n    {"type": "pick", "object": "cup"},\r\n    {"type": "navigate", "x": 0.0, "y": 0.0, "theta": 0.0}\r\n]}"""\r\n        \r\n        self.get_logger().info(\'LLM Task Planner initialized\')\r\n    \r\n    def command_callback(self, msg):\r\n        """Process incoming voice command"""\r\n        command = msg.data\r\n        self.get_logger().info(f\'Received command: {command}\')\r\n        \r\n        # Get task plan from LLM\r\n        task_plan = self.get_task_plan(command)\r\n        \r\n        if task_plan:\r\n            self.execute_task_plan(task_plan)\r\n        else:\r\n            self.get_logger().error(\'Failed to generate task plan\')\r\n    \r\n    def get_task_plan(self, command):\r\n        """\r\n        Use LLM to convert natural language to structured actions.\r\n        \r\n        Args:\r\n            command (str): Natural language command\r\n            \r\n        Returns:\r\n            dict: Structured task plan\r\n        """\r\n        try:\r\n            response = self.client.chat.completions.create(\r\n                model=self.model,\r\n                messages=[\r\n                    {"role": "system", "content": self.system_prompt},\r\n                    {"role": "user", "content": command}\r\n                ],\r\n                temperature=0.3,  # Lower temperature for more deterministic output\r\n                response_format={"type": "json_object"}\r\n            )\r\n            \r\n            # Parse JSON response\r\n            plan_json = response.choices[0].message.content\r\n            plan = json.loads(plan_json)\r\n            \r\n            self.get_logger().info(f\'Generated plan: {plan}\')\r\n            return plan\r\n            \r\n        except Exception as e:\r\n            self.get_logger().error(f\'LLM error: {str(e)}\')\r\n            return None\r\n    \r\n    def execute_task_plan(self, plan):\r\n        """\r\n        Execute the task plan by calling appropriate ROS actions.\r\n        \r\n        Args:\r\n            plan (dict): Task plan with list of actions\r\n        """\r\n        actions = plan.get(\'actions\', [])\r\n        \r\n        for i, action in enumerate(actions):\r\n            action_type = action.get(\'type\')\r\n            \r\n            self.publish_status(f\'Executing action {i+1}/{len(actions)}: {action_type}\')\r\n            \r\n            if action_type == \'navigate\':\r\n                self.execute_navigate(action)\r\n            elif action_type == \'pick\':\r\n                self.execute_pick(action)\r\n            elif action_type == \'place\':\r\n                self.execute_place(action)\r\n            elif action_type == \'wait\':\r\n                self.execute_wait(action)\r\n            else:\r\n                self.get_logger().warn(f\'Unknown action type: {action_type}\')\r\n    \r\n    def execute_navigate(self, action):\r\n        """Execute navigation action"""\r\n        goal = NavigateToPoint.Goal()\r\n        goal.target_x = action[\'x\']\r\n        goal.target_y = action[\'y\']\r\n        goal.target_theta = action.get(\'theta\', 0.0)\r\n        \r\n        self.get_logger().info(f\'Navigating to ({goal.target_x}, {goal.target_y})\')\r\n        \r\n        # Send goal and wait for result\r\n        future = self.nav_client.send_goal_async(goal)\r\n        rclpy.spin_until_future_complete(self, future)\r\n        \r\n        goal_handle = future.result()\r\n        if goal_handle.accepted:\r\n            result_future = goal_handle.get_result_async()\r\n            rclpy.spin_until_future_complete(self, result_future)\r\n            \r\n            result = result_future.result().result\r\n            if result.success:\r\n                self.get_logger().info(\'Navigation completed successfully\')\r\n            else:\r\n                self.get_logger().error(f\'Navigation failed: {result.message}\')\r\n    \r\n    def execute_pick(self, action):\r\n        """Execute pick action"""\r\n        goal = PickObject.Goal()\r\n        goal.object_name = action[\'object\']\r\n        \r\n        self.get_logger().info(f\'Picking object: {goal.object_name}\')\r\n        \r\n        future = self.manip_client.send_goal_async(goal)\r\n        rclpy.spin_until_future_complete(self, future)\r\n        \r\n        # Handle result...\r\n    \r\n    def publish_status(self, status):\r\n        """Publish task status"""\r\n        msg = String()\r\n        msg.data = status\r\n        self.status_pub.publish(msg)\r\n        self.get_logger().info(status)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    planner = LLMTaskPlanner()\r\n    \r\n    try:\r\n        rclpy.spin(planner)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        planner.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"pattern-2-reinforcement-learning-agent",children:"Pattern 2: Reinforcement Learning Agent"}),"\n",(0,a.jsx)(e.h3,{id:"use-case-learned-locomotion-control",children:"Use Case: Learned Locomotion Control"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nRL agent for humanoid locomotion integrated with ROS 2\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import JointState, Imu\r\nfrom std_msgs.msg import Float64MultiArray\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\n\r\nclass RLLocomotionController(Node):\r\n    """\r\n    Reinforcement learning agent for bipedal walking.\r\n    Trained in simulation, deployed via ROS 2.\r\n    """\r\n    \r\n    def __init__(self):\r\n        super().__init__(\'rl_locomotion_controller\')\r\n        \r\n        # Load trained RL model\r\n        self.declare_parameter(\'model_path\', \'models/locomotion_policy.pth\')\r\n        model_path = self.get_parameter(\'model_path\').value\r\n        \r\n        self.policy = self.load_policy(model_path)\r\n        self.policy.eval()  # Set to evaluation mode\r\n        \r\n        # State variables\r\n        self.joint_positions = None\r\n        self.joint_velocities = None\r\n        self.imu_data = None\r\n        self.target_velocity = 0.5  # m/s\r\n        \r\n        # Subscribers for sensor data\r\n        self.joint_sub = self.create_subscription(\r\n            JointState,\r\n            \'joint_states\',\r\n            self.joint_callback,\r\n            10\r\n        )\r\n        \r\n        self.imu_sub = self.create_subscription(\r\n            Imu,\r\n            \'imu/data\',\r\n            self.imu_callback,\r\n            10\r\n        )\r\n        \r\n        # Publisher for joint commands\r\n        self.cmd_pub = self.create_publisher(\r\n            Float64MultiArray,\r\n            \'joint_commands\',\r\n            10\r\n        )\r\n        \r\n        # Control loop timer (50 Hz)\r\n        self.control_timer = self.create_timer(0.02, self.control_loop)\r\n        \r\n        self.get_logger().info(\'RL Locomotion Controller initialized\')\r\n    \r\n    def load_policy(self, model_path):\r\n        """Load trained PyTorch policy network"""\r\n        class PolicyNetwork(nn.Module):\r\n            def __init__(self, state_dim=30, action_dim=12):\r\n                super().__init__()\r\n                self.fc1 = nn.Linear(state_dim, 256)\r\n                self.fc2 = nn.Linear(256, 256)\r\n                self.fc3 = nn.Linear(256, action_dim)\r\n                \r\n            def forward(self, x):\r\n                x = torch.relu(self.fc1(x))\r\n                x = torch.relu(self.fc2(x))\r\n                return torch.tanh(self.fc3(x))\r\n        \r\n        policy = PolicyNetwork()\r\n        policy.load_state_dict(torch.load(model_path))\r\n        return policy\r\n    \r\n    def joint_callback(self, msg):\r\n        """Update joint state"""\r\n        self.joint_positions = np.array(msg.position)\r\n        self.joint_velocities = np.array(msg.velocity)\r\n    \r\n    def imu_callback(self, msg):\r\n        """Update IMU data"""\r\n        self.imu_data = {\r\n            \'angular_velocity\': np.array([\r\n                msg.angular_velocity.x,\r\n                msg.angular_velocity.y,\r\n                msg.angular_velocity.z\r\n            ]),\r\n            \'linear_acceleration\': np.array([\r\n                msg.linear_acceleration.x,\r\n                msg.linear_acceleration.y,\r\n                msg.linear_acceleration.z\r\n            ])\r\n        }\r\n    \r\n    def get_observation(self):\r\n        """\r\n        Construct observation vector for RL policy.\r\n        \r\n        Returns:\r\n            np.array: Observation vector\r\n        """\r\n        if self.joint_positions is None or self.imu_data is None:\r\n            return None\r\n        \r\n        # Combine all sensor data into observation\r\n        obs = np.concatenate([\r\n            self.joint_positions,      # 12 joint positions\r\n            self.joint_velocities,     # 12 joint velocities\r\n            self.imu_data[\'angular_velocity\'],  # 3 angular velocities\r\n            self.imu_data[\'linear_acceleration\'],  # 3 linear accelerations\r\n            [self.target_velocity]     # 1 target velocity\r\n        ])\r\n        \r\n        return obs\r\n    \r\n    def control_loop(self):\r\n        """Main control loop - runs at 50 Hz"""\r\n        obs = self.get_observation()\r\n        \r\n        if obs is None:\r\n            return\r\n        \r\n        # Get action from RL policy\r\n        with torch.no_grad():\r\n            obs_tensor = torch.FloatTensor(obs).unsqueeze(0)\r\n            action_tensor = self.policy(obs_tensor)\r\n            action = action_tensor.squeeze(0).numpy()\r\n        \r\n        # Scale actions to joint torque limits\r\n        max_torque = 50.0  # Nm\r\n        joint_torques = action * max_torque\r\n        \r\n        # Publish joint commands\r\n        cmd_msg = Float64MultiArray()\r\n        cmd_msg.data = joint_torques.tolist()\r\n        self.cmd_pub.publish(cmd_msg)\r\n    \r\n    def set_target_velocity(self, velocity):\r\n        """Update target walking velocity"""\r\n        self.target_velocity = velocity\r\n        self.get_logger().info(f\'Target velocity set to {velocity} m/s\')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    controller = RLLocomotionController()\r\n    \r\n    try:\r\n        rclpy.spin(controller)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        controller.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"pattern-3-state-machine-with-ai-decision-making",children:"Pattern 3: State Machine with AI Decision Making"}),"\n",(0,a.jsx)(e.h3,{id:"use-case-autonomous-behavior-coordination",children:"Use Case: Autonomous Behavior Coordination"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nState machine that coordinates AI decisions with robot actions\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom enum import Enum\r\nimport openai\r\n\r\nclass RobotState(Enum):\r\n    IDLE = 0\r\n    PLANNING = 1\r\n    NAVIGATING = 2\r\n    MANIPULATING = 3\r\n    RECOVERING = 4\r\n\r\nclass AIStateMachine(Node):\r\n    """\r\n    State machine that uses AI for decision-making while\r\n    coordinating ROS actions.\r\n    """\r\n    \r\n    def __init__(self):\r\n        super().__init__(\'ai_state_machine\')\r\n        \r\n        # Initialize AI client\r\n        self.ai_client = openai.Client(api_key=\'your-key\')\r\n        \r\n        # Current state\r\n        self.state = RobotState.IDLE\r\n        self.task_queue = []\r\n        \r\n        # ROS interfaces\r\n        self.setup_ros_interfaces()\r\n        \r\n        # State machine timer (10 Hz)\r\n        self.sm_timer = self.create_timer(0.1, self.state_machine_update)\r\n        \r\n        self.get_logger().info(\'AI State Machine initialized\')\r\n    \r\n    def setup_ros_interfaces(self):\r\n        """Setup ROS publishers, subscribers, action clients"""\r\n        # Implement ROS interface setup\r\n        pass\r\n    \r\n    def state_machine_update(self):\r\n        """Main state machine loop"""\r\n        if self.state == RobotState.IDLE:\r\n            self.handle_idle_state()\r\n        elif self.state == RobotState.PLANNING:\r\n            self.handle_planning_state()\r\n        elif self.state == RobotState.NAVIGATING:\r\n            self.handle_navigating_state()\r\n        elif self.state == RobotState.MANIPULATING:\r\n            self.handle_manipulating_state()\r\n        elif self.state == RobotState.RECOVERING:\r\n            self.handle_recovering_state()\r\n    \r\n    def handle_idle_state(self):\r\n        """Handle IDLE state - wait for new tasks"""\r\n        if self.task_queue:\r\n            self.transition_to(RobotState.PLANNING)\r\n    \r\n    def handle_planning_state(self):\r\n        """Use AI to plan next actions"""\r\n        task = self.task_queue[0]\r\n        \r\n        # Use AI to generate plan\r\n        plan = self.generate_ai_plan(task)\r\n        \r\n        if plan:\r\n            self.execute_plan(plan)\r\n            self.transition_to(RobotState.NAVIGATING)\r\n        else:\r\n            self.get_logger().error(\'Planning failed\')\r\n            self.transition_to(RobotState.RECOVERING)\r\n    \r\n    def generate_ai_plan(self, task):\r\n        """Use AI to generate execution plan"""\r\n        # Implement AI planning logic\r\n        pass\r\n    \r\n    def transition_to(self, new_state):\r\n        """Transition to new state"""\r\n        self.get_logger().info(f\'State transition: {self.state.name} -> {new_state.name}\')\r\n        self.state = new_state\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    sm = AIStateMachine()\r\n    \r\n    try:\r\n        rclpy.spin(sm)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        sm.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"best-practices-for-ai-ros-integration",children:"Best Practices for AI-ROS Integration"}),"\n",(0,a.jsx)(e.h3,{id:"1-separate-concerns",children:"1. Separate Concerns"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class AIDecisionMaker:\r\n    """Pure AI logic - no ROS dependencies"""\r\n    def make_decision(self, state):\r\n        # AI logic here\r\n        pass\r\n\r\nclass ROSBridge(Node):\r\n    """ROS interface only"""\r\n    def __init__(self):\r\n        super().__init__(\'ros_bridge\')\r\n        self.ai = AIDecisionMaker()\r\n        \r\n    def sensor_callback(self, msg):\r\n        state = self.extract_state(msg)\r\n        decision = self.ai.make_decision(state)\r\n        self.execute_decision(decision)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"2-handle-timing-carefully",children:"2. Handle Timing Carefully"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# AI inference might be slow\r\ndef control_loop(self):\r\n    if self.ai_result_ready():\r\n        action = self.get_ai_action()\r\n    else:\r\n        # Use last action or safe default\r\n        action = self.last_action\r\n    \r\n    self.execute_action(action)\n"})}),"\n",(0,a.jsx)(e.h3,{id:"3-implement-safety-checks",children:"3. Implement Safety Checks"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def execute_ai_command(self, command):\r\n    # Validate AI output before executing\r\n    if not self.is_safe(command):\r\n        self.get_logger().warn('Unsafe AI command rejected')\r\n        return False\r\n    \r\n    if not self.is_feasible(command):\r\n        self.get_logger().warn('Infeasible AI command')\r\n        return False\r\n    \r\n    # Execute validated command\r\n    self.execute(command)\r\n    return True\n"})}),"\n",(0,a.jsx)(e.h3,{id:"4-provide-rich-feedback",children:"4. Provide Rich Feedback"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class FeedbackManager:\r\n    \"\"\"Collect and format feedback for AI\"\"\"\r\n    \r\n    def get_state_summary(self):\r\n        return {\r\n            'robot_pose': self.get_pose(),\r\n            'joint_states': self.get_joints(),\r\n            'sensor_data': self.get_sensors(),\r\n            'task_progress': self.get_progress(),\r\n            'errors': self.get_errors()\r\n        }\n"})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"complete-integration-example",children:"Complete Integration Example"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nComplete example: AI-driven humanoid robot controller\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom rclpy.action import ActionClient\r\nimport openai\r\nimport json\r\n\r\nclass HumanoidAIController(Node):\r\n    """\r\n    Complete AI-ROS integration for humanoid robot control.\r\n    Combines LLM planning, RL locomotion, and ROS actions.\r\n    """\r\n    \r\n    def __init__(self):\r\n        super().__init__(\'humanoid_ai_controller\')\r\n        \r\n        # Initialize components\r\n        self.llm_planner = LLMPlanner(self)\r\n        self.rl_controller = RLController(self)\r\n        self.safety_monitor = SafetyMonitor(self)\r\n        \r\n        # ROS interfaces\r\n        self.setup_ros_interfaces()\r\n        \r\n        # Main control loop\r\n        self.create_timer(0.05, self.control_loop)  # 20 Hz\r\n        \r\n        self.get_logger().info(\'Humanoid AI Controller ready\')\r\n    \r\n    def control_loop(self):\r\n        """Main control loop"""\r\n        # 1. Check safety\r\n        if not self.safety_monitor.is_safe():\r\n            self.emergency_stop()\r\n            return\r\n        \r\n        # 2. Get high-level plan from LLM (if needed)\r\n        if self.needs_replanning():\r\n            plan = self.llm_planner.get_plan()\r\n            self.current_plan = plan\r\n        \r\n        # 3. Execute current action with RL controller\r\n        if self.current_plan:\r\n            action = self.current_plan.get_current_action()\r\n            self.rl_controller.execute(action)\r\n        \r\n        # 4. Update state and provide feedback\r\n        self.update_state()\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    controller = HumanoidAIController()\r\n    \r\n    try:\r\n        rclpy.spin(controller)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        controller.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"AI agents provide high-level intelligence"}),"\n",(0,a.jsx)(e.li,{children:"ROS 2 handles low-level robot control"}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.code,{children:"rclpy"})," bridges the two layers"]}),"\n",(0,a.jsx)(e.li,{children:"Separate concerns for maintainability"}),"\n",(0,a.jsx)(e.li,{children:"Implement safety checks"}),"\n",(0,a.jsx)(e.li,{children:"Handle timing differences"}),"\n",(0,a.jsx)(e.li,{children:"Provide rich feedback to AI"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"This integration enables truly intelligent humanoid robots that can understand natural language, learn from experience, and execute complex physical tasks."}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://platform.openai.com/docs",children:"OpenAI API Documentation"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://pytorch.org/tutorials/",children:"PyTorch for Robotics"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://docs.ros.org/en/humble/Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html",children:"ROS 2 Action Servers"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://stable-baselines3.readthedocs.io/",children:"Stable Baselines3 (RL)"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>s});var t=r(6540);const a={},o=t.createContext(a);function i(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:i(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);